Homework 2
========================================================

Myeong Lee
--------------------------------------------------------
  
### Task 1
  
##### H0 in formal expression

$H_0: R^2 = 0$

##### H0 in words expression
- There is no relationship between $X_1$, $X_2$, $X_3$ and y in the population. $X_1$, $X_2$, $X_3$ do not predict y in the population.


### Task 2
  
##### H1 in formal expression
$H_1: R^2 > 0$

##### H1 in words expression
- There is a positive or negative relationship between $X_1$, $X_2$, $X_3$ and y in the population. $X_1$, $X_2$, $X_3$ do predict y in the population.


### Task 3: Error Rate $\alpha$
$\alpha = P(P|H_0) = 0.05$ 


### Task 4: Full-model Regression
```{r}
data1 <- read.csv("C:/Users/myeong/Desktop/hw2.csv")
fit1 <- lm(y ~ X1 + X2 + X3, data=data1)
summary(fit1)

fit2 <- update(fit1, scale(y)~scale(X1)+scale(X2)+scale(X3))
summary(fit2)
```


### Task 5: Sub-model Regression

##### X1 and X2 
```{r}
sub.fit1 <- lm(y ~ X1 + X2, data=data1)
summary(sub.fit1)

sub.fit2 <- update(sub.fit1, scale(y)~scale(X1)+scale(X2))
summary(sub.fit2)
```


##### X1 and X3
```{r}
sub.fit1 <- lm(y ~ X1 + X3, data=data1)
summary(sub.fit1)

sub.fit2 <- update(sub.fit1, scale(y)~scale(X1)+scale(X3))
summary(sub.fit2)
```


### Task 6: Raw-score and the Standardized Prediction Equation

##### Raw-score Prediction Equation

- y = 1.190 + 3.965X1 + 1.421X2 + 4.129X3

##### Standardized Prediction Equation

- y = 0.793X1 + 0.107X2 + 0.382X3  


### Task 7: Time-series plots of y and e

##### y - observation number
```{r}
library(ggplot2)
data1$e <- residuals(fit1)
data1$y.hat <- fitted(fit1)

qplot(1:nrow(data1), y, data=data1, main="Time Series - y", xlab="Obs #", ylab="Values")

```

##### e - observation number
```{r}
qplot(1:nrow(data1), e, data=data1, main="Time Series - e", xlab="Obs #", ylab="residuals")

```

### Task 8: data.frame with y, y_hat, and e for each observation

```{r}
frame1 <- data.frame(y=data1$y, y_hat=data1$y.hat, e=data1$e)
frame1
```


### Task 9: Correlations
```{r, results='asis'}
library(xtable)

cortable <- data1[,c("y","y.hat","e")]
my.cor <- cor(cortable)
print(xtable(my.cor), type="html")

```

### Task 10: Pairwise scatter plots and correlations
```{r}
library(GGally)

ggpairs(cortable, lower=list(continuous="smooth"))

```

### Task 11: Intercorrelations found

- y and y.hat are closely, positively correlated with the coeff 0.957: this means the regression explains the relationship between X1, X2, X3 and y well in some degree.
- y and e are loosely correlated with the coeff 0.289.
- e and y.hat are not correlated by definition.


### Task 12: Interpret the Results

- At $\alpha = .05$, critical t($df_residual$)=t(4)=2.78

##### Confidence Intervals
- $ConfInt_{b1} = 3.965 \pm 2.78 \times 0.852 = 3.965 \pm 2.37$ 
- $ConfInt_{b2} = 1.421 \pm 2.78 \times 2.842 = 1.421 \pm 7.90$
- $ConfInt_{b3} = 4.129 \pm 2.78 \times 2.285 = 4.129 \pm 6.35$

##### Overall interpretation
- Since p-value = 0.0401 < $\alpha = 0.05$, it can be said that the prediction rejects null hypothesis in 95% significance level, but the confidence intervals show high uncertainties in b2 and b3. 

